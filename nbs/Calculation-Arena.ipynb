{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214af6c8-2cc8-42ac-b49a-af4e21f9a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "from collections import Counter\n",
    "import random\n",
    "from datasets import Dataset, IterableDataset, load_from_disk\n",
    "import pickle\n",
    "import numpy as np\n",
    "from phonenumbers import PhoneNumberMatcher\n",
    "import multiprocess as mp\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "from utils import *\n",
    "import detect_en\n",
    "import mask_pii\n",
    "import gopher_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817d7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'big-5p'\n",
    "ds_path = '../data/'+ds_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a0e6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95d416433f24ead81e9100020c2091b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/builder.py:1607\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[1;32m   1606\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1607\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, record \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_shard_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m writer\u001b[38;5;241m.\u001b[39m_num_bytes \u001b[38;5;241m>\u001b[39m max_shard_size:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/packaged_modules/generator/generator.py:33\u001b[0m, in \u001b[0;36mGenerator._generate_examples\u001b[0;34m(self, **gen_kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_examples\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgen_kwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, ex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgenerator(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgen_kwargs)):\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m idx, ex\n",
      "File \u001b[0;32m~/Desktop/clean-corpus/nbs/../scripts/utils.py:73\u001b[0m, in \u001b[0;36mload_ds\u001b[0;34m(ds_name)\u001b[0m\n\u001b[1;32m     72\u001b[0m ds_config \u001b[38;5;241m=\u001b[39m DSS[ds_name]\n\u001b[0;32m---> 73\u001b[0m fs \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_filenames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m get_data_fs(fs, ds_config)\n",
      "File \u001b[0;32m~/Desktop/clean-corpus/nbs/../scripts/utils.py:45\u001b[0m, in \u001b[0;36mget_all_filenames\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     44\u001b[0m paths \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/webz_2022_01-2023_10'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mclean_corpus\u001b[39;00m  \u001b[38;5;66;03m# Import the clean_corpus package\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mclean_corpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_webz_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load the dataset using the function\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Display some information about the loaded dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/clean-corpus/nbs/../clean_corpus/core.py:6\u001b[0m, in \u001b[0;36mload_webz_dataset\u001b[0;34m(ds_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_webz_dataset\u001b[39m(ds_name):\n\u001b[0;32m----> 6\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mds_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/arrow_dataset.py:1108\u001b[0m, in \u001b[0;36mDataset.from_generator\u001b[0;34m(generator, features, cache_dir, keep_in_memory, gen_kwargs, num_proc, split, **kwargs)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a Dataset from a generator.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeneratorDatasetInputStream\n\u001b[0;32m-> 1108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeneratorDatasetInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/io/generator.py:49\u001b[0m, in \u001b[0;36mGeneratorDatasetInputStream.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m     verification_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mas_dataset(\n\u001b[1;32m     57\u001b[0m         split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_in_memory\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/builder.py:924\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 924\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/builder.py:1648\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1648\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_duplicate_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBASIC_CHECKS\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_CHECKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/builder.py:1000\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m-> 1000\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m   1007\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/builder.py:1486\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[0;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1484\u001b[0m job_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[0;32m-> 1486\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m job_id, done, content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split_single(\n\u001b[1;32m   1487\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs, job_id\u001b[38;5;241m=\u001b[39mjob_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_prepare_split_args\n\u001b[1;32m   1488\u001b[0m     ):\n\u001b[1;32m   1489\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   1490\u001b[0m             result \u001b[38;5;241m=\u001b[39m content\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trans/lib/python3.9/site-packages/datasets/builder.py:1643\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, SchemaInferenceError) \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1642\u001b[0m         e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39m__context__\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while generating the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m job_id, \u001b[38;5;28;01mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[38;5;241m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import clean_corpus  # Import the clean_corpus package\n",
    "dataset = clean_corpus.load_webz_dataset(ds_name)  # Load the dataset using the function\n",
    "\n",
    "# Display some information about the loaded dataset\n",
    "print(f\"Loaded dataset: {ds_name}\")\n",
    "print(f\"Number of rows: {len(dataset)}\")\n",
    "print(f\"Features: {dataset.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4125f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2a5cc3-b5af-470f-b98b-a13b348bac2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048577"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**20+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22d99456-1eea-4e57-b335-0ae3fc5fcdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1.3814861993795258\n",
      "1 2 1.4807161803740103\n",
      "2 4 1.2638512605567982\n",
      "3 8 0.2058977094545617\n",
      "4 16 0.793480021811575\n",
      "5 32 0.8836150829883063\n",
      "6 64 0.793209431476516\n",
      "7 128 0.6758602041011978\n",
      "8 256 0.771187107911777\n",
      "9 512 0.6637006609256471\n",
      "10 1024 0.6388875338494893\n",
      "11 2048 0.6310464773338049\n",
      "12 4096 0.6168976865518092\n",
      "13 8192 0.6225843255781469\n",
      "14 16384 0.6360176222606685\n",
      "15 32768 0.6296328563037465\n",
      "16 65536 0.6370584854917849\n",
      "17 131072 0.6343303249709334\n",
      "18 262144 0.6373374175702228\n",
      "19 524288 0.6371410419837418\n",
      "20 1048576 0.6375264413644244\n",
      "21 2097152 0.6364633804144381\n",
      "22 4194304 0.636754711018467\n",
      "23 8388608 0.6365915541482641\n",
      "24 16777216 0.6365119388001268\n",
      "25 33554432 0.6366154405499375\n",
      "26 67108864 0.6364970505904106\n",
      "27 134217728 0.6366934333549402\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for d in range(28):\n",
    "    x=np.random.normal(0, 1, 2**d)\n",
    "    y=np.random.normal(0, 1, 2**d)\n",
    "    m=np.absolute((x*y)).mean()\n",
    "    print(d,2**d,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45556229-b7a9-47af-9e55-fab99c61e379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57ee63-5c36-42bf-9b56-86aa20da16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl = {}\n",
    "for ds_name in DSS.keys():\n",
    "    curl[ds_name] = Counter(site(x) for x in load_ds(ds_name))\n",
    "    with open(f'curl_{ds_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(curl[ds_name], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b308ac-3f41-46f2-8e25-e1f5d9b4d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_generator(load_ds, gen_kwargs={'ds_name':ds_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf2508e-ecdc-48d1-ae66-13fa965012e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'url', 'en_proba', 'erased_mail', 'n_erased_mail', 'erased_phone', 'n_erased_phone', 'gopher_verdict', 'sentences', 'sentences_normalized', 'dedup_text', 'erased_dedup', 'dedup_diff'],\n",
       "    num_rows: 199332\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds = load_from_disk(ds_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be190a-24b6-455b-9300-d0f8800f3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.add_column(\"id\", list(range(len(ds))))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c112f-28b3-4e0c-b050-8c8160efe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_en.erase_model()\n",
    "ds=ds.map(detect_en.calculate_english, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63befb6-1294-4782-a456-a7ca89ad1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.map(mask_pii.calculate_masked_pii, fn_kwargs={'mask_entity':'mail'}, batched=True, num_proc=4)\n",
    "ds=ds.map(mask_pii.calculate_masked_pii, fn_kwargs={'mask_entity':'phone'}, batched=True, num_proc=4)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a7dd8-70de-4619-b024-6e8a0556abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.map(gopher_filter.calculate_gopher, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112066f-186f-4c78-92c7-8840a0c13d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sentences = ds.map(dedup.apply_normalization, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc060582-48bb-433d-a453-d46e409b92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup.calculate_sentence_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e71f3-ac90-4847-a170-749f7d526624",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(dedup.erase_duplicates, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820d6f6-ee03-4af2-b529-8a9fa49bc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_classifiers.erase_engines()\n",
    "ds = ds.map(transformers_classifiers.calculate_score, batched=True, batch_size=16, fn_kwargs={'score_label':'hate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2fc06-20ea-472a-b22e-5e8a64d33333",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_classifiers.erase_engines()\n",
    "ds = ds.map(transformers_classifiers.calculate_score, batched=True, batch_size=16, fn_kwargs={'score_label':'nsfw'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5bca0-8a2c-482b-8c44-a6595389d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_nsfw_lines()\n",
    "a=ds.map(check_is, batched=True,num_proc=4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52936ee3-74ed-43dd-be51-f3bf90ea35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acum=np.zeros(len(lines),dtype=int)\n",
    "cases=np.zeros(len(lines),dtype=int)\n",
    "for i,x in enumerate(tqdm(a)):\n",
    "    is_present = np.array(x['is_present'],dtype=int)\n",
    "    cases[is_present==1]=i\n",
    "    acum += is_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c93bb-f68a-4617-b883-ac56f49e6379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b05375-2320-4d1e-a3c2-18f5c0963beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92f33fa-499a-44dc-ada8-d321fc161176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99978822, 0.99982971, 0.99979931, ..., 0.99972016, 0.99968553,\n",
       "       0.99992025])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_proba = np.array(ds['en_proba'])\n",
    "en_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d8f224-4f89-41fe-8e0d-42d55e31366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4135612947243796"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(en_proba)<0.65).item()*100/len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71117d9-c4ee-4c50-a82e-491d0b11d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(en_proba[en_proba>0.993], bins=50, edgecolor='black')\n",
    "plt.title('Histogram of en_proba')\n",
    "plt.xlabel('en_proba')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9491cb8-ed1c-439f-a653-b0575cec55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english_erased.log', 'w') as f:\n",
    "    for x in ds.shuffle().select(range(500)).filter(lambda x : x['en_proba']<0.65):\n",
    "        pprint(x, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fe372-c312-454a-b7ac-06b4241af964",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_erased_mail = np.array(ds['n_erased_mail'])\n",
    "\n",
    "sum(n_erased_emails>0).item()*100/len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df1672-569f-4458-8260-c560973c1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mail_masked.log', 'w') as f:\n",
    "    for x in ds.shuffle().select(range(250)).filter(lambda x : x['n_erased_mail']>0):\n",
    "        pprint(x, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc474e4-dd1a-4ddc-b374-c07dc6616224",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_erased_phone = np.array(ds['n_erased_phone'])\n",
    "n_erased_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e75f18-b39c-40f8-88a9-c8f9d2317c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(n_erased_phone>0).item()*100/len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9a901-6847-46ce-b991-c3cabbae02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phone_masked.log', 'w') as f:\n",
    "    for x in ds.shuffle().select(range(250)).filter(lambda x : x['n_erased_phone']>0):\n",
    "        pprint(x, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a39d00-7d02-4547-9972-826ee24308fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few_words: 6.067264663977685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986fcd697d02438abd53e50c5792847a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many_words: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1711ba3a3e4630a587e52bb1f3f6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_words: 0.02608713101759878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a6e11529c64a78b0672aaed260e72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_words: 0.08729155378965746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f228b99eb5244288b4425a7df9badc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ellipsis: 0.0702345835089198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dc52e8357749c9bb8e74de7a2957a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few_alpha: 7.714767322858347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047fc9c8738942159a7b6ae08759094c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gopher_verdict = np.array(ds['gopher_verdict'])\n",
    "\n",
    "for err in gopher_filter.GOPHER_ERROR:\n",
    "    print(f'{err}: {(gopher_verdict==err).sum().item()*100/len(ds)}')\n",
    "    with open(f'gopher_{err}_erased.log', 'w') as f:\n",
    "        for x in ds.shuffle().select(range(10000)).filter(lambda x : x['gopher_verdict']==err).select(range(3)):\n",
    "            pprint(x, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4a076-7a11-45cd-8ceb-92005f19ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=ds.filter(lambda batch : ['{' in x or '}' in x for x in batch['text']], batched=True)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91c3bb-8428-4e95-8d1a-e2269c99da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_count_sorted = sorted(list(sentence_count.items()), key=lambda x : -x[1])\n",
    "short_sentences = []\n",
    "for s,c in sentence_count_sorted:\n",
    "    s=s.replace('<SEP>','').replace('<PAD>','')\n",
    "    if len(s.split())==1 and c>2:\n",
    "        short_sentences.append((s,c))\n",
    "short_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec76d4a-62b7-4461-83f6-60beedf7edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.filter(lambda x : len(x['dedup_text'])==0))*100/len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522272a-0faa-4f23-b90d-e9730d0e8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(x) for x in tqdm(ds['dedup_text']))*100/sum(len(x) for x in tqdm(ds['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf84974-c5f1-43bd-b860-50e8f8d69c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(x) for x in tqdm(ds['erased_dedup']))*100/sum(len(x) for x in tqdm(ds['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e722b9-5287-4728-a670-050efa9670c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond(x):\n",
    "    return x['en_proba']>0.65 and x['gopher_verdict']=='ok' and len(x['erased_dedup'])>0\n",
    "                                                                    \n",
    "with open('erased_dedup.log', 'w') as f:\n",
    "    for x in ds.shuffle().select(range(250)).filter(cond):\n",
    "        pprint(x, body_field='dedup_diff', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2cb7e-9135-425d-8c86-4223c81d4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting and selecting the top-20 counts\n",
    "top_indices = np.argsort(acum)[-60:-20][::-1]  # Indices of top-20 counts in descending order\n",
    "top_tags = [lines[i] for i in top_indices]\n",
    "top_counts = acum[top_indices]*100 / len(ds)\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(top_tags, top_counts, edgecolor='black')\n",
    "plt.xlabel('Tags')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Histogram of Top-20 Tag Counts')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (trans)",
   "language": "python",
   "name": "trans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
